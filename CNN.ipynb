{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# self.bn = nn.BatchNorm2d(64)\n",
    "# self.mp = nn.MaxPool2d(kernel_size = (12,22),stride =(1,1))\n",
    "# self.dp = nn.Dropout(p=0.2)\n",
    "# self.sm = nn.Softmax(dim = 0)\n",
    "# self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=0)\n",
    "# self.relu1 = nn.ReLU()\n",
    "# self.maxpool1 = nn.MaxPool2d(kernel_size=4)\n",
    "# self.fc1 = nn.Linear(576, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1 : Build your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class My_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(My_Model, self).__init__()\n",
    "\n",
    "        # Convolution 1\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=0)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=4)\n",
    "        self.fc1 = nn.Linear(576, 10)\n",
    "    def forward(self, x):\n",
    "        out = self.cnn1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.maxpool1(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2 : Load input and label ,convert them to torch variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ep', 0)\n",
      "(array([3, 9, 3, 3, 3, 3, 3, 2, 3]), array([3, 9, 0, 6, 5, 0, 9, 4, 1]))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.dataset import Dataset  # For custom datasets\n",
    "import random\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_path):\n",
    "\n",
    "        # Transforms\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        \n",
    "        # Read the csv file\n",
    "        self.data_info = pd.read_csv(csv_path, header=None)\n",
    "\n",
    "        # First column is image paths\n",
    "        self.path_arr = np.asarray(self.data_info.iloc[:, 0])\n",
    "        \n",
    "        # Second column is the labels\n",
    "        self.label_arr = np.asarray(self.data_info.iloc[:, 1])\n",
    "        \n",
    "        # Calculate sample counts\n",
    "        self.data_len = len(self.data_info.index)\n",
    "\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "\n",
    "        path = self.path_arr[index]\n",
    "\n",
    "\n",
    "#         x = np.load(path)['arr_0']\n",
    "        x = Image.open(path)\n",
    "\n",
    "        #start preprocess data\n",
    "\n",
    "        #end preprocess data\n",
    "        \n",
    "#         x = torch.from_numpy(x)\n",
    "        x = self.to_tensor(x)\n",
    "\n",
    "        label = int(self.label_arr[index])\n",
    "        \n",
    "        return (x.float(), label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "\n",
    "\n",
    "custom_data = CustomDataset('./train.csv')\n",
    "\n",
    "\n",
    "dataset_loader = torch.utils.data.DataLoader(dataset=custom_data,\n",
    "                                                batch_size=10,\n",
    "                                                shuffle=True)\n",
    "\n",
    "model = My_Model()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer =  torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "epoch = 1\n",
    "\n",
    "# Clear gradients\n",
    "# optimizer.zero_grad()\n",
    "\n",
    "for ep in range(epoch):\n",
    "    print('ep',ep)\n",
    "    for i, (x, labels) in enumerate(dataset_loader):\n",
    "        x = Variable(x)\n",
    "        labels = Variable(labels)\n",
    "        # Forward pass\n",
    "        outputs = model(x)\n",
    "        \n",
    "        # Calculate loss \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "\n",
    "    _,idx = torch.max(outputs, 1)\n",
    "    print(idx.data.numpy(),labels.data.numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ep', 0)\n",
      "Variable containing:\n",
      "1.00000e-02 *\n",
      "  1.3286\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "(array([8, 4, 4, 0, 9, 3, 5, 6, 9, 5]), array([8, 4, 4, 0, 9, 3, 5, 6, 9, 5]))\n"
     ]
    }
   ],
   "source": [
    "epoch = 10\n",
    "\n",
    "for ep in range(epoch):\n",
    "\n",
    "    for i, (xs, labels) in enumerate(dataset_loader):\n",
    "        xs = Variable(xs)\n",
    "        labels = Variable(labels)\n",
    "        # Forward pass\n",
    "        outputs = model(xs)\n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        if i == 0: \n",
    "            _,idx = torch.max(outputs, 1)\n",
    "            \n",
    "            if ep%10 ==0:\n",
    "                print('ep',ep)\n",
    "                print(loss)\n",
    "                print(idx.data.numpy(),labels.data.numpy())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
